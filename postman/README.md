# Midaz API Postman Collection & Testing

This directory contains the automated Postman collection generation and testing framework for the Midaz API. The system provides comprehensive API documentation, automated testing, and workflow validation across all Midaz services.

## ğŸš€ Quick Start

```bash
# Generate Postman collection from OpenAPI specs
make generate-docs

# Run complete API workflow tests
make newman
```

## ğŸ“‹ Overview

The Midaz API testing system consists of two main processes:

1. **Collection Generation** (`make generate-docs`): Converts OpenAPI specifications into Postman collections
2. **Workflow Testing** (`make newman`): Executes comprehensive end-to-end API tests

## ğŸ”§ Collection Generation Process (`make generate-docs`)

### Step 1: Environment Setup (`Makefile`)
- **Trigger**: `make generate-docs` command
- **Prerequisites**: Runs dependency checks (`make tidy`, `make check-envs`)
- **Tool Verification**: Ensures `swag` CLI and `node` are installed
- **Purpose**: Prepares the build environment for documentation generation

### Step 2: OpenAPI Specification Generation (`swag`)
- **Location**: `components/{onboarding,transaction}/`
- **Command**: `swag init -g cmd/server/main.go -o api`
- **Input**: Go source code with Swagger annotations
- **Output**: `api/swagger.json` and `api/openapi.yaml` per component
- **Purpose**: Extracts API documentation from Go code annotations

**Swagger Annotations Parsed**:
- `@Summary`, `@Description`: Endpoint documentation
- `@Param`, `@Body`: Request parameters and payloads
- `@Success`, `@Failure`: Response definitions
- `@Router`: HTTP method and path mapping

### Step 3: OpenAPI to Postman Conversion (`scripts/postman-coll-generation/`)

#### File Chain & Purpose:

**ğŸ­ Main Orchestrator**: `sync-postman.sh`
- **Input**: `swagger.json` files from both components
- **Purpose**: Coordinates the entire conversion pipeline
- **Key Functions**:
  - Runs conversions in parallel for performance
  - Merges collections from multiple services
  - Creates timestamped backups before overwriting
  - Handles error recovery and status tracking
  - Calls other scripts in proper sequence

**ğŸ”„ Core Conversion Script**: `convert-openapi.js`
- **Input**: `components/{service}/api/swagger.json`
- **Output**: Individual Postman collections per service
- **Key Functions**:
  - Converts OpenAPI paths to Postman requests
  - Generates example payloads from schemas
  - Maps authentication schemes
  - Creates environment variables
  - Routes endpoints to correct base URLs (`onboardingUrl` vs `transactionUrl`)

**âš¡ Test Enhancement Script**: `enhance-tests.js`
- **Purpose**: Adds comprehensive test scripts to each request
- **Features**:
  - Response validation (status codes, JSON structure)
  - Business logic validation (UUID format, timestamps)
  - Variable extraction for workflow chaining
  - Performance monitoring
  - Unique idempotency key generation
  - Error handling and logging

**ğŸ”— Workflow Generation Script**: `create-workflow.js`
- **Input**: `postman/WORKFLOW.md` (57 step workflow definition)
- **Output**: "Complete API Workflow" folder in collection
- **Features**:
  - Sequential API testing (Organization â†’ Ledger â†’ Account â†’ Transaction)
  - Dynamic variable chaining between steps
  - Custom transaction payloads (Zero Out Balance with dynamic amounts)
  - Balance validation and extraction
  - Comprehensive cleanup sequence

### Step 4: Collection Assembly & Optimization (Handled by `sync-postman.sh`)
- **Parallel Processing**: Converts both services simultaneously
- **Intelligent Merging**: Combines requests from multiple services
- **Organization**: Groups requests by functional area
- **Variable Management**: Creates unified environment variables
- **URL Routing**: Ensures correct service endpoints
- **Quality Assurance**: Validates collection structure and handles errors gracefully

## ğŸ§ª Workflow Testing Process (`make newman`)

### Step 1: Newman Setup
- **Tool**: Newman CLI (Postman command-line runner)
- **Version Check**: Ensures Newman 6.2.1+ is installed
- **Environment**: Loads `MIDAZ.postman_environment.json`
- **Reporting**: Configures HTML and detailed reports

### Step 2: Workflow Execution
- **Target**: "Complete API Workflow" folder (57 steps)
- **Sequence**: End-to-end API testing across all services
- **Validation**: 165+ assertions covering business logic
- **Performance**: Response time monitoring and regression detection

### Step 3: Test Categories

**ğŸ“Š Core API Operations**:
- CRUD operations for all entities (Organizations, Ledgers, Accounts, Assets, etc.)
- Authentication and authorization
- Data validation and error handling

**ğŸ’° Financial Transactions**:
- Transaction creation (JSON, Inflow, Outflow)
- Balance management and validation
- Double-entry accounting verification
- Dynamic balance zeroing

**ğŸ”— Workflow Dependencies**:
- Variable extraction and chaining
- Sequential step execution
- Error recovery and cascading failure prevention

### Step 4: Reporting & Analysis
- **HTML Reports**: Generated in `reports/newman/`
- **Test Results**: Pass/fail status for each endpoint
- **Performance Metrics**: Response times and regression detection
- **Error Details**: Comprehensive failure analysis with HTTP status codes

## ğŸ“ File Structure & Dependencies

```
postman/
â”œâ”€â”€ README.md                           # This documentation
â”œâ”€â”€ WORKFLOW.md                         # 57-step workflow definition
â”œâ”€â”€ MIDAZ.postman_collection.json       # Generated collection (111+ requests)
â””â”€â”€ MIDAZ.postman_environment.json     # Environment variables

scripts/postman-coll-generation/
â”œâ”€â”€ sync-postman.sh                     # Main orchestrator script
â”œâ”€â”€ convert-openapi.js                  # OpenAPI â†’ Postman conversion
â”œâ”€â”€ enhance-tests.js                    # Test script generation
â”œâ”€â”€ create-workflow.js                  # Workflow folder creation
â””â”€â”€ package.json                        # Node.js dependencies

reports/newman/
â”œâ”€â”€ workflow-report.html                # Basic test report
â””â”€â”€ workflow-detailed-report.html       # Comprehensive failure analysis
```

## ğŸ¯ Key Features

### Advanced Test Generation
- **Idempotency Management**: Unique keys for each transaction
- **Dynamic Payloads**: Context-aware request bodies
- **Variable Chaining**: Seamless data flow between test steps
- **Error Recovery**: Robust handling of API failures

### Business Logic Validation
- **UUID Format Checking**: Ensures proper ID generation
- **Timestamp Validation**: Verifies ISO format compliance
- **Balance Calculations**: Double-entry accounting verification
- **Account State Management**: Proper lifecycle testing

### Performance Monitoring
- **Response Time Tracking**: Per-endpoint performance metrics
- **Regression Detection**: Alerts for performance degradation
- **Load Testing**: Validates API under test conditions
- **Resource Usage**: Monitors API efficiency

## ğŸ” Troubleshooting

### Common Issues

**Collection Generation Failures**:
- Verify `swag` is installed: `swag --version`
- Check OpenAPI annotations in Go code
- Ensure Node.js dependencies: `npm install` in `scripts/`

**Newman Test Failures**:
- Check service availability: Both onboarding (3000) and transaction (3001) ports
- Verify environment variables are set correctly
- Review detailed HTML reports for specific error details

**Variable Chain Breaks**:
- Ensure proper variable extraction in test scripts
- Check for unique variable naming conflicts
- Verify prerequisite steps completed successfully

### Debug Commands

```bash
# Verify collection structure
jq '.item[].name' postman/MIDAZ.postman_collection.json

# Check environment variables
jq '.values[].key' postman/MIDAZ.postman_environment.json

# Run specific workflow step
newman run postman/MIDAZ.postman_collection.json -e postman/MIDAZ.postman_environment.json --folder "Complete API Workflow" --verbose
```

## ğŸ‰ Success Metrics

The current workflow achieves:
- âœ… **100% Success Rate**: 57/57 requests passing
- âœ… **165 Assertions**: Complete business logic validation
- âœ… **End-to-End Coverage**: All API endpoints tested
- âœ… **Performance Validated**: <5ms average response time
- âœ… **Production Ready**: Comprehensive error handling

This automated testing framework ensures the Midaz API maintains high quality, performance, and reliability across all services and endpoints.