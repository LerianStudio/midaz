# Midaz API Postman Collection & Testing

This directory contains the automated Postman collection generation and testing framework for the Midaz API. The system provides API documentation, automated testing, and workflow validation across all Midaz services.

## Quick Start

```bash
# Generate Postman collection from OpenAPI specs
make generate-docs

# Run complete API workflow tests
make newman
```

## Overview

The Midaz API testing system has two main processes:

1. **Collection Generation** (`make generate-docs`): Converts OpenAPI specifications into Postman collections
2. **Workflow Testing** (`make newman`): Executes end-to-end API tests

## Collection Generation Process (`make generate-docs`)

### Step 1: Environment Setup (`Makefile`)
- **Trigger**: `make generate-docs` command
- **Prerequisites**: Runs dependency checks (`make tidy`, `make check-envs`)
- **Tool Verification**: Ensures `swag` CLI and `node` are installed via `setup-deps.sh`
- **Purpose**: Prepares the build environment for documentation generation

### Step 2: OpenAPI Specification Generation (`scripts/generate-docs.sh`)
- **Orchestrator**: Clean, beautified wrapper around the generation process
- **Components**: Processes `onboarding` and `transaction` services
- **Command**: `swag init -g cmd/app/main.go -o api --parseDependency --parseInternal`
- **Input**: Go source code with Swagger annotations
- **Output**: `api/swagger.json` and `api/swagger.yaml` per component
- **Features**: Progress tracking, error handling, timing metrics, log abstraction

**Swagger Annotations Parsed**:
- `@Summary`, `@Description`: Endpoint documentation
- `@Param`, `@Body`: Request parameters and payloads
- `@Success`, `@Failure`: Response definitions
- `@Router`: HTTP method and path mapping

### Step 3: OpenAPI to Postman Conversion (`scripts/postman-coll-generation/`)

#### File Chain & Purpose:

**Main Orchestrator**: `sync-postman.sh`
- **Input**: `swagger.json` files from both components
- **Purpose**: Coordinates the entire conversion pipeline
- **Key Functions**:
  - Runs conversions in parallel for performance
  - Merges collections from multiple services
  - Creates timestamped backups before overwriting
  - Handles error recovery and status tracking
  - Calls other scripts in proper sequence

**Core Conversion Script**: `convert-openapi.js`
- **Input**: `components/{service}/api/swagger.json`
- **Output**: Individual Postman collections per service
- **Key Functions**:
  - Converts OpenAPI paths to Postman requests
  - Generates example payloads from schemas
  - Maps authentication schemes
  - Creates environment variables
  - Routes endpoints to correct base URLs (`onboardingUrl` vs `transactionUrl`)

**Test Enhancement Script**: `enhance-tests.js`
- **Purpose**: Adds comprehensive test scripts to each request
- **Features**:
  - Response validation (status codes, JSON structure)
  - Business logic validation (UUID format, timestamps)
  - Variable extraction for workflow chaining
  - Performance monitoring
  - Unique idempotency key generation
  - Error handling and logging

**Workflow Generation Script**: `create-workflow.js`
- **Input**: `postman/WORKFLOW.md` (57 step workflow definition)
- **Output**: "Complete API Workflow" folder in collection
- **Features**:
  - Sequential API testing (Organization → Ledger → Account → Transaction)
  - Dynamic variable chaining between steps
  - Custom transaction payloads (Zero Out Balance with dynamic amounts)
  - Balance validation and extraction
  - Comprehensive cleanup sequence

### Step 4: Collection Assembly & Optimization (Handled by `sync-postman.sh`)
- **Parallel Processing**: Converts both services simultaneously
- **Intelligent Merging**: Combines requests from multiple services
- **Organization**: Groups requests by functional area
- **Variable Management**: Creates unified environment variables
- **URL Routing**: Ensures correct service endpoints
- **Quality Assurance**: Validates collection structure and handles errors gracefully

## Workflow Testing Process (`make newman`)

### Step 1: Newman Setup
- **Tool**: Newman CLI (Postman command-line runner)
- **Version Check**: Ensures Newman 6.2.1+ is installed
- **Environment**: Loads `MIDAZ.postman_environment.json`
- **Reporting**: Configures HTML and detailed reports

### Step 2: Workflow Execution
- **Target**: "Complete API Workflow" folder (57 steps)
- **Sequence**: End-to-end API testing across all services
- **Validation**: 165+ assertions covering business logic
- **Performance**: Response time monitoring and regression detection

### Step 3: Test Categories

**Core API Operations**:
- CRUD operations for all entities (Organizations, Ledgers, Accounts, Assets, etc.)
- Authentication and authorization
- Data validation and error handling

**Financial Transactions**:
- Transaction creation (JSON, Inflow, Outflow)
- Balance management and validation
- Double-entry accounting verification
- Dynamic balance zeroing

**Workflow Dependencies**:
- Variable extraction and chaining
- Sequential step execution
- Error recovery and cascading failure prevention

### Step 4: Reporting & Analysis
- **HTML Reports**: Generated in `reports/newman/`
- **Test Results**: Pass/fail status for each endpoint
- **Performance Metrics**: Response times and regression detection
- **Error Details**: Comprehensive failure analysis with HTTP status codes

## File Structure & Dependencies

```
postman/
├── README.md                           # This documentation
├── WORKFLOW.md                         # 57-step workflow definition
├── MIDAZ.postman_collection.json       # Generated collection (111+ requests)
└── MIDAZ.postman_environment.json     # Environment variables

scripts/
├── generate-docs.sh                    # Clean generation orchestrator
├── setup-deps.sh                       # Dependency setup and validation
└── postman-coll-generation/
    ├── sync-postman.sh                 # Collection merging and workflow creation
    ├── convert-openapi.js              # OpenAPI → Postman conversion
    ├── enhance-tests.js                # Test script generation
    ├── create-workflow.js              # Workflow folder creation
    └── package.json                    # Node.js dependencies

reports/newman/
├── workflow-report.html                # Basic test report
└── workflow-detailed-report.html       # Comprehensive failure analysis
```

## Key Features

### Advanced Test Generation
- **Idempotency Management**: Unique keys for each transaction
- **Dynamic Payloads**: Context-aware request bodies
- **Variable Chaining**: Seamless data flow between test steps
- **Error Recovery**: Robust handling of API failures

### Business Logic Validation
- **UUID Format Checking**: Ensures proper ID generation
- **Timestamp Validation**: Verifies ISO format compliance
- **Balance Calculations**: Double-entry accounting verification
- **Account State Management**: Proper lifecycle testing

### Performance Monitoring
- **Response Time Tracking**: Per-endpoint performance metrics
- **Regression Detection**: Alerts for performance degradation
- **Load Testing**: Validates API under test conditions
- **Resource Usage**: Monitors API efficiency

## Troubleshooting

### Common Issues

**Collection Generation Failures**:
- Verify `swag` is installed: `swag --version`
- Check OpenAPI annotations in Go code
- Ensure Node.js dependencies: `npm install` in `scripts/`

**Newman Test Failures**:
- Check service availability: Both onboarding (3000) and transaction (3001) ports
- Verify environment variables are set correctly
- Review detailed HTML reports for specific error details

**Variable Chain Breaks**:
- Ensure proper variable extraction in test scripts
- Check for unique variable naming conflicts
- Verify prerequisite steps completed successfully

### Debug Commands

```bash
# Verify collection structure
jq '.item[].name' postman/MIDAZ.postman_collection.json

# Check environment variables
jq '.values[].key' postman/MIDAZ.postman_environment.json

# Run specific workflow step
newman run postman/MIDAZ.postman_collection.json -e postman/MIDAZ.postman_environment.json --folder "Complete API Workflow" --verbose
```

## Success Metrics

A successful test run typically shows:
- **100% Success Rate**: Example: 57/57 requests passing
- **Full Assertion Coverage**: Example: 165+ assertions validating business logic
- **End-to-End Coverage**: All API endpoints tested
- **Fast Response Times**: Target: <5ms average response time
- **Production Ready**: Comprehensive error handling verified

This automated testing framework ensures the Midaz API maintains high quality, performance, and reliability across all services and endpoints.
